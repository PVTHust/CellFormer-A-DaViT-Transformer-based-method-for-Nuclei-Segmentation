# -*- coding: utf-8 -*-
"""Cell_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SlnUCGB6lCoNWF63jrVzMcA51wO0o0AB
"""

class Cell_Former(nn.Module):

    def __init__(self,backbone,depths=(16,32,32,64)):
        super(Cell_Former, self).__init__()
        self.backbone = backbone
        self.attention0=MSCAttention(96,32)
        self.attention1=MSCAttention(96*2,32)
        self.attention2=MSCAttention(96*4,16)
        self.attention3=MSCAttention(96*8,8)
        self.conv = BasicConv2d(96,32, 3,1,1)
        self.mea = MEA(32)
        self.linear_fuse=ConvModule(320,64*8)
        self.lawin=LawinHead(64*8)
        self.RB=RB(64*8,32)
        self.sba = SBA(32)
        self.Multi = nn.ModuleList([])
        for i in range(4):
          self.Multi.append(nn.Sequential(
                    RB([96*8, 96*4+64, 96*8, 96*8][i], [64,64,64,64][i]), RB(64, 64), nn.Upsample(size=depths[i])))
        self.Up=nn.Upsample(size=256)
        self.Up1=nn.Upsample(size=64)
        self.Near=nn.Sequential(
                RB(64, 64), RB(64, 64))
        self.End=  nn.Sequential(
                RB(64, 64), RB(64, 64), nn.Conv2d(64, 1, kernel_size=1))
    def forward(self, x):

        pyramid=self.backbone.get_features(x)
        pyramid0 = pyramid[0]
        py1 = self.attention1(pyramid[1])
        py2 = self.attention2(pyramid[2])
        py3 = self.attention3(pyramid[3])
        py0=self.conv(pyramid0)
        py3mix=self.Multi[0](py3)
        py3mix_adv=self.Multi[2](py3)
        py3cat=torch.cat((py3mix,py2),dim=1)
        py2mix=self.Multi[1](py3cat)
        py2cat=torch.cat((py2mix,py1,py3mix_adv),dim=1)
        input=self.linear_fuse(py2cat)

        output=self.lawin(input)

        output = self.RB(output)
        output = torch.cat((py0,F.interpolate(self.mea(output),scale_factor=2,mode='bilinear', align_corners=False)),dim=1)


        feat=self.Near(output)
        feat_concat=self.Up(feat)
        out=self.End(feat_concat)
        return out

from torchsummary import summary
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)
model = Cell_Former(backbone_mm)
model = model.to(device)
